{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import zipfile \n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import csv\n",
    "import random\n",
    "from bs4 import BeautifulSoup\n",
    "import progressbar\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_common = ['GESTION/NOJO',\n",
    "                'GESTION/TETIER_R4',\n",
    "                'GESTION/NOM_HTML',\n",
    "                'DONNEES/IDENT/NOM',\n",
    "                'DONNEES/IDENT/PRM',\n",
    "                'DONNEES/IDENT/ADRESSE',\n",
    "                'DONNEES/IDENT/CP',\n",
    "                'DONNEES/IDENT/VILLE',\n",
    "                'DONNEES/IDENT/MEL',\n",
    "                'DONNEES/IDENT/TEL',\n",
    "                'DONNEES/OBJET/OBJET_COMPLET'\n",
    "                ]\n",
    "\n",
    "#give_me_the_tag = ['DONNEES/INFO',\n",
    "                   #'DONNEES/TYPE_ACTIVITE_ORG']\n",
    "\n",
    "paths_take_all = ['DONNEES/CLASSES',\n",
    "                  'DONNEES/DESCRIPTEURS',\n",
    "                  'DONNEES/CARACTERISTIQUES']\n",
    "\n",
    "jump_a_line = ['DONNEES/PROCEDURES/LOTS']\n",
    "\n",
    "tags = []\n",
    "for path in paths_common:\n",
    "    tags.append(path2tag(path))\n",
    "for path in paths_take_all:\n",
    "    tags.append(path2tag(path))\n",
    "tags.append('LOTS')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path2tag(path):\n",
    "    pavel = ''\n",
    "    for i in reversed(path):\n",
    "        if i != '/':\n",
    "            pavel += i\n",
    "        if i == '/':\n",
    "            break\n",
    "    return pavel[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_me_your_dict(annonce):\n",
    "    lots = []\n",
    "    out = {}\n",
    "    if annonce.find('DONNEES/PROCEDURES/LOTS') is not None:\n",
    "        reslit = list(annonce.find('DONNEES/PROCEDURES/LOTS').iter())\n",
    "    else:\n",
    "        return out\n",
    "    \n",
    "    if reslit is not None:\n",
    "        for element in reslit:\n",
    "            if element.tag == 'NUM_LOT' and element.text is not None:\n",
    "                sub_list = []\n",
    "                for lot_element in reslit[reslit.index(element):]:\n",
    "                    sub_list.append(lot_element)\n",
    "                    if reslit.index(lot_element) + 1 < len(reslit):\n",
    "                        next_element = reslit[reslit.index(lot_element) + 1]\n",
    "                \n",
    "                        if next_element.tag == 'NUM_LOT' and next_element.text is not None:\n",
    "                            lots.append(sub_list)\n",
    "                            break\n",
    "    for arr in lots:\n",
    "        out[lots.index(arr)] = {element.tag: element.text for element in arr}\n",
    "    \n",
    "    out = json.dumps(out, ensure_ascii=False)\n",
    "        \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"  \\n    if len(lots) > 0:\\n        rows.append(lots[0])\\n        rowsamarr.append(rows)\\n        if len(lots) > 1:\\n            for lot in lots[1:]:\\n                row = ['.' for i in range(len(tags) - 1)]\\n                row.append(lot)\\n                rowsamarr.append(row)\\n    else:\\n        rowsamarr.append(rows)\\n\""
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def xml_parser(paths_common, paths_take_all, file):\n",
    "    rowsamarr = []\n",
    "    rows = []\n",
    "    \n",
    "    for path in paths_common:\n",
    "        element = file.find(path)\n",
    "        if element is not None:\n",
    "            if element.text is not None:\n",
    "                rows.append(element.text)\n",
    "            else:\n",
    "                rows.append('.')\n",
    "        elif element is None:\n",
    "            rows.append('.')\n",
    "    \"\"\"\n",
    "    for path in give_me_the_tag:\n",
    "        element = file.find(path)\n",
    "        pavel = ''\n",
    "        if element is not None:\n",
    "            for child in element.getchildren():\n",
    "                if child is not None:\n",
    "                    pavel += child.tag\n",
    "            pairs.append([path2tag(path), pavel])\n",
    "        elif element is None:\n",
    "            pairs.append([path2tag(path), ''])\n",
    "    \"\"\"     \n",
    "    \n",
    "    for path in paths_take_all:\n",
    "        element = file.find(path)\n",
    "        if element is not None:\n",
    "            reslist = list(element.iter()) \n",
    "            result = ' '.join([element.text for element in reslist if element.text is not None])\n",
    "            rows.append(result)\n",
    "        elif element is None:\n",
    "            rows.append('.')\n",
    "    \n",
    "    lots = give_me_your_dict(file)\n",
    "    if lots is not None:\n",
    "        rows.append(lots)\n",
    "    else: \n",
    "        rows.append('.')\n",
    "    return rows, tags \n",
    "\"\"\"  \n",
    "    if len(lots) > 0:\n",
    "        rows.append(lots[0])\n",
    "        rowsamarr.append(rows)\n",
    "        if len(lots) > 1:\n",
    "            for lot in lots[1:]:\n",
    "                row = ['.' for i in range(len(tags) - 1)]\n",
    "                row.append(lot)\n",
    "                rowsamarr.append(row)\n",
    "    else:\n",
    "        rowsamarr.append(rows)\n",
    "\"\"\"        \n",
    "#  return rows, tags \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_csv(big_row_list, file_name, tags, year):\n",
    "    \n",
    "    with open('{}.csv'.format(file_name), 'w') as file:\n",
    "        spamwriter = csv.writer(file, delimiter=';', quotechar='\"',\n",
    "                            quoting=csv.QUOTE_ALL)\n",
    "        spamwriter.writerow(tags)\n",
    "        for row in big_row_list:\n",
    "            spamwriter.writerow(row)\n",
    "        print('wrote {} rows for year {}'.format(len(big_row_list), year))\n",
    "        \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pbar(maxlen, text=''):\n",
    "    \n",
    "    bar = progressbar.ProgressBar(maxval=maxlen, \\\n",
    "    widgets=[progressbar.Bar('=', '[', ']'), text, progressbar.Percentage(), ' (', progressbar.ETA(), ') '])\n",
    "    \n",
    "    bar.start()\n",
    "    \n",
    "    return bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_years2csv(start, end):\n",
    "    \n",
    "    years = [start + i for i in range(end - start + 1)]\n",
    "\n",
    "    \n",
    "    for i in range(len(years)):\n",
    "        paths = glob.glob('{}/mp*/*.xml'.format(years[i]))\n",
    "        #paths = glob.glob('rand/*.xml')\n",
    "        annonces = []\n",
    "    \n",
    "        bar = pbar(len(paths), ' reading {} data'.format(years[i]))\n",
    "        \n",
    "    \n",
    "        for path in paths:\n",
    "            bar.update(paths.index(path))\n",
    "            file = open(path, encoding='Latin-1')\n",
    "            apple = file.read()\n",
    "\n",
    "            apple = apple.replace('&apos;', \"'\")\n",
    "            apple = apple.replace('&deg;', '°')\n",
    "            apple = apple.replace('&quot;', '\"')\n",
    "            apple = apple.replace('\\t', '')\n",
    "            apple = apple.replace(',', '')\n",
    "            apple = apple.replace('\\n', '')\n",
    "            apple = apple.replace('é', 'e')\n",
    "            apple = apple.replace('ç', 'c')\n",
    "            apple = apple.replace('è', 'e')\n",
    "            apple = apple.replace(':', '')\n",
    "            apple = apple.replace('à', 'a')\n",
    "            apple = apple.replace('ù', 'u')\n",
    "            apple = apple.replace('ê', 'e') #il y a forcément un moyen plus simple\n",
    "\n",
    "            tree = ET.fromstring(apple)\n",
    "            a = tree.getchildren()\n",
    "    \n",
    "            annonces.append(a)\n",
    "    \n",
    "        pavel = []\n",
    "        bar2 = pbar(len(annonces), ' parsing {} data'.format(years[i]))\n",
    "        for annonce in annonces:\n",
    "            bar2.update(annonces.index(annonce))\n",
    "            for j in range(len(annonce)):\n",
    "                extracted_annonce, tags = xml_parser(paths_common, paths_take_all, annonce[j])\n",
    "                pavel.append(extracted_annonce)\n",
    "                \n",
    "        write_to_csv(pavel, years[i], tags, years[i])\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[==================================== ] parsing 2005 data 99% (ETA:   0:00:00) "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote 181247 rows for year 2005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[==================================== ] parsing 2006 data 99% (ETA:   0:00:00) "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote 200116 rows for year 2006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[==================================== ] parsing 2007 data 99% (ETA:   0:00:00) "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote 195950 rows for year 2007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[==================================== ] parsing 2008 data 99% (ETA:   0:00:00) "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote 180415 rows for year 2008\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[==================================== ] parsing 2009 data 99% (ETA:   0:00:00) "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote 177523 rows for year 2009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[==================================== ] parsing 2010 data 99% (ETA:   0:00:00) "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote 176872 rows for year 2010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[==================================== ] parsing 2011 data 99% (ETA:   0:00:00) "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote 27217 rows for year 2011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[==================================== ] parsing 2012 data 99% (ETA:   0:00:00) "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote 178858 rows for year 2012\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[==================================== ] parsing 2013 data 99% (ETA:   0:00:00) "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote 175458 rows for year 2013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[==================================== ] parsing 2014 data 99% (ETA:   0:00:00) "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote 165084 rows for year 2014\n"
     ]
    }
   ],
   "source": [
    "write_years2csv(2005, 2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'apojfezeijg;;;;'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'apojfezeijg'"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.replace(';', '')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
