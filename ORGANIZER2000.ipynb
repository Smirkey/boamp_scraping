{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import zipfile \n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import csv\n",
    "import random\n",
    "from bs4 import BeautifulSoup\n",
    "import progressbar\n",
    "import numpy as np\n",
    "from collections import deque\n",
    "import json\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths_common = ['GESTION/TETIER_R4',\n",
    "                'GESTION/NOJO', # #\n",
    "                'GESTION/NOM_HTML', #\n",
    "                'DONNEES/IDENT/NOM',\n",
    "                'DONNEES/IDENT/PRM',\n",
    "                'DONNEES/IDENT/ADRESSE',\n",
    "                'DONNEES/IDENT/CP',\n",
    "                'DONNEES/IDENT/VILLE',\n",
    "                'DONNEES/IDENT/MEL',\n",
    "                'DONNEES/IDENT/TEL',\n",
    "                'DONNEES/OBJET/OBJET_COMPLET']\n",
    "\n",
    "give_me_the_tag = ['DONNEES/INFO',\n",
    "                   'DONNEES/TYPE_ACTIVITE_ORG']\n",
    "\n",
    "paths_take_all = ['DONNEES/CLASSES/CLASSE']#,\n",
    "                  #'DONNEES/DESCRIPTEURS',\n",
    "                  #'DONNEES/CARACTERISTIQUES']\n",
    "\n",
    "\n",
    "paths_common_2K15 = ['GESTION/REFERENCE/IDWEB',\n",
    "                     'GESTION/NOM_HTML',\n",
    "                     'DONNEES/IDENTITE/DENOMINATION',\n",
    "                     'DONNEES/IDENTITE/CORRESPONDANT',\n",
    "                     'DONNEES/IDENTITE/ADRESSE',\n",
    "                     'DONNEES/IDENTITE/CP',\n",
    "                     'DONNEES/IDENTITE/VILLE',\n",
    "                     'DONNEES/IDENTITE/MEL',\n",
    "                     'DONNEES/IDENTITE/TEL',\n",
    "                     'DONNEES/OBJET/OBJET_COMPLET'\n",
    "                     'DONNEES/OBJET/CPV/PRINCIPAL']\n",
    "\n",
    "give_me_the_tag_2K15 = ['GESTION/REFERENCE/TYPE_AVIS/NATURE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def path2tag(path):\n",
    "    pavel = ''\n",
    "    for i in reversed(path):\n",
    "        if i != '/':\n",
    "            pavel += i\n",
    "        if i == '/':\n",
    "            break\n",
    "    return pavel[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tags(year):\n",
    "    tags = []\n",
    "    return ['NATURE','IDWEB','NOM_HTML','DENOMINATION','CORRESPONDANT','ADRESSE','CP','VILLE','MEL','TEL','CLASSE','DECISIONS']\n",
    "    if year in [2005 + i for i in range(10)]:\n",
    "        \n",
    "        for path in paths_common:\n",
    "            tags.append(path2tag(path))\n",
    "        \n",
    "        for path in paths_take_all:\n",
    "            tags.append(path2tag(path))\n",
    "        \n",
    "        tags.append('LOTS')\n",
    "        return tags\n",
    "    \n",
    "    elif year in [2015 + i for i in range(4)]:\n",
    "        \n",
    "        for path in give_me_the_tag_2K15:\n",
    "            tags.append(path2tag(path))\n",
    "            \n",
    "        for path in paths_common_2K15:\n",
    "            tags.append(path2tag(path))\n",
    "        \n",
    "        tags.append('DECISIONS')\n",
    "        return tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NATURE',\n",
       " 'IDWEB',\n",
       " 'NOM_HTML',\n",
       " 'DENOMINATION',\n",
       " 'CORRESPONDANT',\n",
       " 'ADRESSE',\n",
       " 'CP',\n",
       " 'VILLE',\n",
       " 'MEL',\n",
       " 'TEL',\n",
       " 'PRINCIPAL',\n",
       " 'DECISIONS']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_tags(2015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def give_me_your_dict(annonce):\n",
    "    lots = []\n",
    "    out = {}\n",
    "    if annonce.find('DONNEES/PROCEDURES/LOTS') is not None:\n",
    "        reslit = list(annonce.find('DONNEES/PROCEDURES/LOTS').iter())\n",
    "    else:\n",
    "        return out\n",
    "    \n",
    "    if reslit is not None:\n",
    "        for element in reslit:\n",
    "            if element.tag == 'NUM_LOT' and element.text is not None:\n",
    "                sub_list = []\n",
    "                for lot_element in reslit[reslit.index(element):]:\n",
    "                    sub_list.append(lot_element)\n",
    "                    if reslit.index(lot_element) + 1 < len(reslit):\n",
    "                        next_element = reslit[reslit.index(lot_element) + 1]\n",
    "                \n",
    "                        if next_element.tag == 'NUM_LOT' and next_element.text is not None:\n",
    "                            lots.append(sub_list)\n",
    "                            break\n",
    "    for arr in lots:\n",
    "        out[lots.index(arr)] = {element.tag: element.text for element in arr}\n",
    "    \n",
    "    out = json.dumps(out, ensure_ascii=False)\n",
    "        \n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xml_parser(paths_common, paths_take_all, file):\n",
    "    rowsamarr = []\n",
    "    rows = []\n",
    "    \n",
    "    for path in paths_common:\n",
    "        element = file.find(path)\n",
    "        if element is not None:\n",
    "            if element.text is not None:\n",
    "                rows.append(element.text)\n",
    "            else:\n",
    "                rows.append('.')\n",
    "        elif element is None:\n",
    "            rows.append('.')\n",
    "    \n",
    "    for path in paths_take_all:\n",
    "        element = file.find(path)\n",
    "        if element is not None:\n",
    "            reslist = list(element.iter()) \n",
    "            result = ' '.join([element.text for element in reslist if element.text is not None])\n",
    "            rows.append(result)\n",
    "        elif element is None:\n",
    "            rows.append('.')\n",
    "    \n",
    "    lots = give_me_your_dict(file)\n",
    "    if lots is not None:\n",
    "        rows.append(lots)\n",
    "    else: \n",
    "        rows.append('.')\n",
    "    return rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision2dic(decision):\n",
    "    dic = {}\n",
    "    reslit = list(decision.iter())\n",
    "    for element in reslit:\n",
    "        if element.text is not None:\n",
    "            dic[element.tag] = element.text\n",
    "    return dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xml_parser3000(paths_common, give_me_the_tag, file):\n",
    "    rows = []\n",
    "    \n",
    "    for path in give_me_the_tag:\n",
    "        rows.append(file.find(path).getchildren()[0].tag)\n",
    "    \n",
    "    for path in paths_common:\n",
    "        element = file.find(path)\n",
    "        if element is not None:\n",
    "            if element.text is not None:\n",
    "                rows.append(element.text)\n",
    "            else:\n",
    "                rows.append('.')\n",
    "        elif element is None:\n",
    "            rows.append('.')\n",
    "    \n",
    "    dic = {}\n",
    "    k = 0\n",
    "    decision = file.find('DONNEES/ATTRIBUTION')\n",
    "    if decision is not None:\n",
    "        children = decision.getchildren()\n",
    "        for child in children:\n",
    "            if child.tag == 'DECISION':\n",
    "                dic[k] = decision2dic(child)\n",
    "                k+=1\n",
    "    dic = json.dumps(dic, ensure_ascii=False)\n",
    "    rows.append(dic)     \n",
    "    return rows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_to_csv(big_row_list, file_name, year):\n",
    "    \n",
    "    with open('{}.csv'.format(file_name), 'w') as file:\n",
    "        spamwriter = csv.writer(file, delimiter=';', quotechar='\"',\n",
    "                            quoting=csv.QUOTE_ALL)\n",
    "        spamwriter.writerow(get_tags(year))\n",
    "        for row in big_row_list:\n",
    "            spamwriter.writerow(row)\n",
    "        print('wrote {} rows for year {}'.format(len(big_row_list), year))\n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pbar(maxlen, text=''):\n",
    "    \n",
    "    bar = progressbar.ProgressBar(maxval=maxlen, \\\n",
    "    widgets=[progressbar.Bar('=', '[', ']'), text, progressbar.Percentage(), ' (', progressbar.ETA(), ') '])\n",
    "    \n",
    "    bar.start()\n",
    "    \n",
    "    return bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_my_apple(apple):\n",
    "    \n",
    "    apple = apple.replace('&apos;', \"'\")\n",
    "    apple = apple.replace('&deg;', '°')\n",
    "    apple = apple.replace('&quot;', '\"')\n",
    "    apple = apple.replace('\\t', '')\n",
    "    apple = apple.replace(',', '')\n",
    "    apple = apple.replace('\\n', '')\n",
    "    apple = apple.replace('é', 'e')\n",
    "    apple = apple.replace('ç', 'c')\n",
    "    apple = apple.replace('è', 'e')\n",
    "    apple = apple.replace(':', '')\n",
    "    apple = apple.replace('à', 'a')\n",
    "    apple = apple.replace('ù', 'u')\n",
    "    clean_apple = apple.replace('ê', 'e')\n",
    "    \n",
    "    return clean_apple "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_years2csv(start, end):\n",
    "    \n",
    "    years = [start + i for i in range(end - start + 1)]\n",
    "\n",
    "    \n",
    "    for i in range(len(years)):\n",
    "        if years[i] < 2015:\n",
    "            paths = glob.glob('{}/mp*/*.xml'.format(years[i]))\n",
    "        #paths = glob.glob('rand/*.xml')\n",
    "            annonces = []\n",
    "    \n",
    "            bar = pbar(len(paths), ' reading {} data'.format(years[i]))\n",
    "        \n",
    "    \n",
    "            for path in paths:\n",
    "                bar.update(paths.index(path))\n",
    "                file = open(path, encoding='Latin-1')\n",
    "                apple = file.read()\n",
    "\n",
    "                apple = clean_my_apple(apple) #il y a forcément un moyen plus simple\n",
    "\n",
    "                tree = ET.fromstring(apple)\n",
    "                a = tree.getchildren()\n",
    "    \n",
    "                annonces.append(a)\n",
    "    \n",
    "            pavel = []\n",
    "            bar2 = pbar(len(annonces), ' parsing {} data'.format(years[i]))\n",
    "            for annonce in annonces:\n",
    "                bar2.update(annonces.index(annonce))\n",
    "                for j in range(len(annonce)):\n",
    "                    extracted_annonce = xml_parser(paths_common, paths_take_all, annonce[j])\n",
    "                    pavel.append(extracted_annonce)\n",
    "                \n",
    "            write_to_csv(pavel, years[i], years[i])\n",
    "            \n",
    "        if years[i] > 2014:\n",
    "            \n",
    "            paths = glob.glob('{}/BOAMP-*/*.xml'.format(years[i]))\n",
    "            annonces = []\n",
    "            pavel = []\n",
    "            bar4 = pbar(len(paths), ' reading {} data'.format(years[i]))\n",
    "\n",
    "            for j in range(len(paths)):\n",
    "                bar4.update(j)\n",
    "                file = open(paths[j], encoding = 'utf-8')\n",
    "                \n",
    "                apple = clean_my_apple(file.read())\n",
    "                \n",
    "                tree = ET.fromstring(apple)\n",
    "                annonces.append(tree)\n",
    "                \n",
    "                file.close()\n",
    "            \n",
    "            bar5 = pbar(len(annonces), ' parsing {} data'.format(years[i]))\n",
    "\n",
    "            for j in range(len(annonces)):\n",
    "                \n",
    "                bar5.update(j)\n",
    "                extracted_annonce = xml_parser3000(paths_common_2K15, give_me_the_tag_2K15, annonces[j])\n",
    "                pavel.append(extracted_annonce)\n",
    "            \n",
    "            write_to_csv(pavel, years[i], years[i])\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[=                                    ] reading 2005 data  4% (ETA:   0:03:13) "
     ]
    }
   ],
   "source": [
    "write_years2csv(2005, 2018)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
